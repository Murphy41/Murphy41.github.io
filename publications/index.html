<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="6Rl6I9VGcfHIMuLbwwVecnXxolJ7jGZvtegRgYl-wMo"> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Yangmengfei Xu </title> <meta name="author" content="Yangmengfei Xu"> <meta name="description" content="PhD Student in Robotics at the University of Melbourne. "> <meta name="keywords" content="robotics, HCI, HRI, cotrol system, smart home"> <meta property="og:site_name" content="Yangmengfei Xu"> <meta property="og:type" content="website"> <meta property="og:title" content="Yangmengfei Xu | publications"> <meta property="og:url" content="https://Murphy41.github.io/publications/"> <meta property="og:description" content="PhD Student in Robotics at the University of Melbourne. "> <meta property="og:image" content="/assets/img/photo2.PNG"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="publications"> <meta name="twitter:description" content="PhD Student in Robotics at the University of Melbourne. "> <meta name="twitter:image" content="/assets/img/photo2.PNG"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Yangmengfei Xu"
        },
        "url": "https://Murphy41.github.io/publications/",
        "@type": "WebSite",
        "description": "PhD Student in Robotics at the University of Melbourne.
",
        "headline": "publications",
        
        "sameAs": [null,"https://scholar.google.com/citations?user=xGVR6cQAAAAJ"],
        
        "name": "Yangmengfei Xu",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://murphy41.github.io/publications/"> <script src="/assets/js/theme.js?v=48c9b5bd7f2e0605e39e579400e22553"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Yangmengfei</span> Xu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <script src="/assets/js/bibsearch.js?v=1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CHI EA</abbr> <figure> <picture> <img src="/assets/img/publication_preview/chi2025_preview.svg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="chi2025_preview.svg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="li2025modeling" class="col-sm-8"> <div class="title">Modeling Higher-order Human Beliefs Using the Justified Perspective Model</div> <div class="author"> Wanchun Li, Chenyuan Zhang, Weijia Li, Guang Hu, and <em>Yangmengfei Xu</em> </div> <div class="periodical"> <em>In Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>, Apr 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3706599.3720223" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">DOI</a> <a href="https://doi.org/10.1145/3706599.3720223" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a> <a href="/assets/pdf/2025%20Li%20Wanchun%20%5BCHI%20EA%5D%20-%20Modeling%20Higher-order%20Human%20Beliefs%20Using%20the%20Justified%20Perspective%20Model.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="/assets/pdf/CHI25Poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=xGVR6cQAAAAJ&amp;citation_for_view=xGVR6cQAAAAJ:_FxGoFyzp5QC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>This study explores the feasibility of modeling higher-order human beliefs using a generalizable formalization based on the epistemic planning framework, the Justified Perspective (JP) model. Specifically, it investigates (a) whether individuals exhibit consistent belief reasoning abilities and (b) whether these abilities can be inferred from their nesting capabilities within the JP model framework. To address these questions, we propose a novel processing algorithm inspired by Item Response Theory to estimate reasoning abilities based on participants’ responses to diverse reasoning scenarios. A pilot experiment was conducted to validate the methodology and refine the experimental design for future studies. While the small sample size limits the statistical significance of the findings, preliminary results suggest the JP model’s potential to capture human higher-order beliefs. This work demonstrates the promise of integrating epistemic planning frameworks with human-centered applications, advancing the development of Human Computer Interaction systems capable of understanding and anticipating human cognition.</p> </div> </div> </div></li> <li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">HRI</abbr> <figure> <picture> <img src="/assets/img/publication_preview/koalahri2025preview.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="koalahri2025preview.jpeg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xu2025neighbor" class="col-sm-8"> <div class="title">From Isolation to Connection: Community Service Robots for Social Cohesion and Sustainability</div> <div class="author"> <em>Yangmengfei Xu</em>, Suxuan Tian, Guojing Wang, and Bin Tang </div> <div class="periodical"> <em>In 2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</em>, Melbourne, Australia, Mar 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/HRI61500.2025.10973824" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">DOI</a> <a href="https://doi.org/10.1109/HRI61500.2025.10973824" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a> <a href="/assets/pdf/2025%20Xu%20%5BHRI%5D%20-%20From%20Isolation%20to%20Connection%20-%20Community%20Service%20Robots%20for%20Social%20Cohesion%20and%20Sustainability.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="/assets/video/HRI2025Koala.mp4" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a> <a href="/assets/pdf/HRI25Poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=xGVR6cQAAAAJ&amp;citation_for_view=xGVR6cQAAAAJ:ufrVoPGSRksC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Social alienation challenges community cohesion, particularly in diverse societies like Australia. This study introduces the Neighbor Koala, a community-sharing robot designed to foster social connections and promote sustainability. By facilitating item exchanges and capturing shared memories, it aims to address isolation while reducing waste. Leveraging the sociological concept of the “gift”, it strengthens emotional bonds and community belonging. This work provides a cornerstone for future studies on how robotics can enhance social well-being and environmental responsibility in urban contexts.</p> </div> </div> </div></li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Unmanned Syst</abbr> <figure> <picture> <img src="/assets/img/publication_preview/us2024_conn_preview.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="us2024_conn_preview.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="li2024geometry" class="col-sm-8"> <div class="title">A Geometry-Based Distributed Connectivity Maintenance Algorithm for Discrete-time Multi-Agent Systems with Visual Sensing Constraints</div> <div class="author"> Xiaoli Li, Jinyun Fu, Mingliang Liu, <em>Yangmengfei Xu</em>, <a href="https://findanexpert.unimelb.edu.au/profile/28203-ying-tan" rel="external nofollow noopener" target="_blank">Ying Tan</a>, Yangbin Xin, <a href="https://findanexpert.unimelb.edu.au/profile/833203-ye-pu" rel="external nofollow noopener" target="_blank">Ye Pu</a>, and <a href="https://findanexpert.unimelb.edu.au/profile/188333-denny-oetomo" rel="external nofollow noopener" target="_blank">Denny Oetomo</a> </div> <div class="periodical"> <em>Unmanned Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1142/S2301385024410097" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">DOI</a> <a href="https://doi.org/10.1142/S2301385024410097" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a> <a href="/assets/pdf/2023%20Li%20Xiaoli%20%5BUnmanned%20System%5D%20-%20A%20Geometry-Based%20Distributed%20Connectivity%20Maintenance%20Algorithm%20for%20Discrete-time%20Multi-Agent%20Systems%20with%20Visual%20Sensing%20Constraints.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://youtu.be/7-7tG9dLZNk?si=UmxjfA8-LopIEEtO" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Video</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=xGVR6cQAAAAJ&amp;citation_for_view=xGVR6cQAAAAJ:Tyk-4Ss8FVUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>This paper presents a novel approach to address the challenge of maintaining connectivity within a multi-agent system (MAS) when utilizing directional visual sensors. These sensors have become essential tools for enhancing communication and connectivity in MAS, but their geometric constraints pose unique challenges when designing controllers. Our approach, grounded in geometric principles, leverages a mathematical model of directional visual sensors and employs a gradient-descent optimization method to determine the position and orientation constraints for each sensor based on its geometric configuration. This methodology ensures network connectivity, provided that initial geometric constraints are met. Experimental results validate the efficacy of our approach, highlighting its practical applicability for a range of tasks within MAS.</p> </div> </div> </div></li> <li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Unmanned Syst</abbr> <figure> <picture> <img src="/assets/img/publication_preview/adrc.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="adrc.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="liu2024active" class="col-sm-8"> <div class="title">On Active Disturbance Rejection Control for Unmanned Tracked Ground Vehicles with Nonsmooth Disturbances</div> <div class="author"> Mingliang Liu, <em>Yangmengfei Xu</em>, Xuteng Lin, <a href="https://findanexpert.unimelb.edu.au/profile/28203-ying-tan" rel="external nofollow noopener" target="_blank">Ying Tan</a>, <a href="https://findanexpert.unimelb.edu.au/profile/833203-ye-pu" rel="external nofollow noopener" target="_blank">Ye Pu</a>, <a href="https://findanexpert.unimelb.edu.au/profile/847810-wen-li" rel="external nofollow noopener" target="_blank">Wen Li</a>, and <a href="https://findanexpert.unimelb.edu.au/profile/188333-denny-oetomo" rel="external nofollow noopener" target="_blank">Denny Oetomo</a> </div> <div class="periodical"> <em>Unmanned Systems</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1142/S2301385024500353" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">DOI</a> <a href="https://doi.org/10.1142/S2301385024500353" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a> <a href="/assets/pdf/2023%20Liu%20Mingliang%20%5BUnmanned%20System%5D%20-%20On%20Active%20Disturbance%20Rejection%20Control%20for%20Unmanned%20Tracked%20Ground%20Vehicles%20with%20Nonsmooth%20Disturbances.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=xGVR6cQAAAAJ&amp;citation_for_view=xGVR6cQAAAAJ:zYLM7Y9cAGgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>This paper proposes robust controllers for a class of unmanned tracked ground vehicles (UTGVs), which are built to autonomously clean carryback or spillage from the conveyor belts used in the mining industry. The UTGV, a nonholonomic system in its nature, needs to follow a given path in a harsh environment with large uncertainties due to the time-varying mass and inertia when the UTGV loads and unloads as well as unknown frictions and flatness of the ground. Moreover, the input constraints coming from motors do exist. It is usually hard to design robust controllers for such complex systems. By utilizing the available autonomous driving system, which is designed to be compatible with the existing remote motion controller in unmanned systems to generate autonomous ability, this paper uses the off-the-shelf motion planner to calculate desired linear and angular velocities based on the given path and sensor perceptions. Consequently, the control design can be simplified as two decoupled linear time-invariant scalar dynamic systems with uncertainties, making the active disturbance rejection controller (ADRC) applicable. By carefully designing the parameters of ADRC with the help of an extended state observer (ESO), it is shown that the proposed ADRC and ESO can achieve good tracking performance in the presence of input saturation and can handle nonsmooth disturbances. The proposed simulation results and experimental results support the theoretical findings.</p> </div> </div> </div></li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IROS WS</abbr> <figure> <picture> <img src="/assets/img/publication_preview/pypose.svg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="pypose.svg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhan2023pypose" class="col-sm-8"> <div class="title">PyPose v0.6: The Imperative Programming Interface for Robotics</div> <div class="author"> Zitong Zhan, Xiangfu Li, Qihang Li, Haonan He, Abhinav Pandey, Haitao Xiao, <em>Yangmengfei Xu</em>, Xiangyu Chen, Kuan Xu, Kun Cao, and <span class="more-authors" title="click to view 26 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '26 more authors' ? 'Zhipeng Zhao, Zihan Wang, Huan Xu, Zihang Fang, Yutian Chen, Wentao Wang, Xu Fang, Yi Du, Tianhao Wu, Xiao Lin, Yuheng Qiu, Fan Yang, Jingnan Shi, Shaoshu Su, Yiren Lu, Taimeng Fu, Karthik Dantu, Jiajun Wu, Lihua Xie, Marco Hutter, Luca Carlone, Sebastian Scherer, Daning Huang, Yaoyu Hu, Junyi Geng, Chen Wang' : '26 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">26 more authors</span> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="Non-archival Workshop Paper"> </i> </div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) Workshop</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2309.13035" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">arXiv</a> <a href="/assets/pdf/2023%20Zhan%20Zitong%20%5BIROS%20WS%5D%20-%20PyPose%20v0.6%20-%20The%20Imperative%20Programming%20Interface%20for%20Robotics.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://youtu.be/XDtUDIWuGng?si=LB1hWbPGhJ8NS5_q" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Video</a> <a href="https://github.com/pypose/pypose" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a> <a href="https://pypose.org" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Website</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=xGVR6cQAAAAJ&amp;citation_for_view=xGVR6cQAAAAJ:W7OEmFMy1HYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-9-4285F4?logo=googlescholar&amp;labelColor=beige" alt="9 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>PyPose is an open-source library for robot learning. It combines a learning-based approach with physicsbased optimization, which enables seamless end-to-end robot learning. It has been used in many tasks due to its meticulously designed application programming interface (API) and efficient implementation. From its initial launch in early 2022, PyPose has experienced significant enhancements, incorporating a wide variety of new features into its platform. To satisfy the growing demand for understanding and utilizing the library and reduce the learning curve of new users, we present the fundamental design principle of the imperative programming interface, and showcase the flexible usage of diverse functionalities and modules using an extremely simple Dubins car example. We also demonstrate that the PyPose can be easily used to navigate a real quadruped robot with a few lines of code.</p> </div> </div> </div></li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MPhil Thesis</abbr> <figure> <picture> <img src="/assets/img/publication_preview/unimelb.svg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="unimelb.svg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xu2022thesis" class="col-sm-8"> <div class="title">Inducing human movement pattern change</div> <div class="author"> <em>Yangmengfei Xu</em> </div> <div class="periodical"> <em>The University of Melbourne</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://hdl.handle.net/11343/311948" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a> <a href="/assets/pdf/2022%20Xu%20%5BThesis%5D%20Inducing%20human%20movement%20pattern%20change.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Human’s movement pattern shaping is widely used in neurorehabilitation and sports training. Recent studies have shown that robotic device has its potential to become an efficient tool for clinicians to induce this change. To understand human’s movement, different computational models were proposed and studied to explain how human resolves their redundancy. Although some arguments are still existing, the general idea of optimization has been well accepted. Based on these computational models, the motor learning studies showed that through practice in the new environment, the reward-based optimization could drive human to search for a better movement pattern 1) to maximize the performance and 2) to minimize the motor cost. Leveraging this optimization idea in human motor learning, this work aims to induce the movement pattern changes in an experimental setup solely relying on the motor cost without any explicit kinematic error. In this strategy, the intervention space and adaptation space are decoupled: while the force field only applies to the hand linear velocity, the adaptation is expected to happen in the redundant arm joint space (i.e. the swivel angle). This work, therefore, explores the following topics: * Investigating the feasibility of inducing human motor adaptation in the redundant space by providing a task space intervention without explicit error feedback or instruction; * Evaluating the contribution of a progressively changing goal in this implicit motor adaptation, assuming that this adaptation may be further promoted through subtle prompts to explore the cost space; * Demonstrating a motor cost analysis based on the upper limb kinematics and dynamics model to validate the relationship between observations and motor cost.</p> </div> </div> </div></li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TNSRE</abbr> <figure> <picture> <img src="/assets/img/publication_preview/emu.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="emu.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xu2021inducing" class="col-sm-8"> <div class="title">Inducing Human Motor Adaptation Without Explicit Error Feedback: A Motor Cost Approach</div> <div class="author"> <em>Yangmengfei Xu</em>, <a href="https://findanexpert.unimelb.edu.au/profile/624368-vincent-crocher" rel="external nofollow noopener" target="_blank">Vincent Crocher</a>, <a href="https://findanexpert.unimelb.edu.au/profile/643118-justin-fong" rel="external nofollow noopener" target="_blank">Justin Fong</a>, <a href="https://findanexpert.unimelb.edu.au/profile/28203-ying-tan" rel="external nofollow noopener" target="_blank">Ying Tan</a>, and <a href="https://findanexpert.unimelb.edu.au/profile/188333-denny-oetomo" rel="external nofollow noopener" target="_blank">Denny Oetomo</a> </div> <div class="periodical"> <em>IEEE Transactions on Neural Systems and Rehabilitation Engineering</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TNSRE.2021.3096516" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">DOI</a> <a href="https://doi.org/10.1109/TNSRE.2021.3096516" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a> <a href="/assets/pdf/2021%20Xu%20%5BTNSRE%5D%20-%20Inducing%20human%20motor%20adaptation%20without%20explicit%20error%20feedback%20A%20motor%20cost%20approach.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=xGVR6cQAAAAJ&amp;citation_for_view=xGVR6cQAAAAJ:u-x6o8ySG0sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-9-4285F4?logo=googlescholar&amp;labelColor=beige" alt="9 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Recent studies have shown that motor adaptation is an optimisation process on both kinematic error and effort. This work aims to induce a motor adaption in an experimental setup solely relying on the effort without any explicit kinematic error. In this experiment, the intervention space and adaptation space are decoupled: while the force field only applies to the hand linear velocity, the adaptation is expected to happen in the arm joint null space (i.e. the swivel angle). The primary hypothesis is that such an effort-based force field can induce a movement pattern change in an indirect manner. Secondarily, assuming that this adaptation may be further promoted through subtle prompts to explore the cost space, a variation of the approach with a progressive goal is also tested. Twenty naive subjects were allocated into two groups with slightly different implementations of the force field: one with a Constant Goal (CG) and another one with a Progressively changing Goal (PG). Subjects were asked to perform reaching tasks while attached to a 3D manipulandum. During the intervention, the device applied a resistive viscous force at the subject’s hand as a function of the subject’s swivel angle to encourage an increase of the latter. Significant increases of the swivel angle of 4.9° and 6.3° were observed for the CG and the PG groups respectively. This result confirms the feasibility of inducing motor adaptation in the redundant joint space by providing a task space intervention without explicit error feedback.</p> </div> </div> </div></li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Sensors</abbr> <figure> <picture> <img src="/assets/img/publication_preview/sensors19preview.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sensors19preview.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mohammadi2019magnetic" class="col-sm-8"> <div class="title">Magnetic-based Soft Tactile Sensors with Deformable Continuous Force Transfer Medium for Resolving Contact Locations in Robotic Grasping and Manipulation</div> <div class="author"> <a href="https://findanexpert.unimelb.edu.au/profile/344558-alireza-mohammadi" rel="external nofollow noopener" target="_blank">Alireza Mohammadi</a>, <em>Yangmengfei Xu</em>, <a href="https://findanexpert.unimelb.edu.au/profile/28203-ying-tan" rel="external nofollow noopener" target="_blank">Ying Tan</a>, <a href="https://findanexpert.unimelb.edu.au/profile/2266-peter-choong" rel="external nofollow noopener" target="_blank">Peter Choong</a>, and <a href="https://findanexpert.unimelb.edu.au/profile/188333-denny-oetomo" rel="external nofollow noopener" target="_blank">Denny Oetomo</a> </div> <div class="periodical"> <em>Sensors</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3390/s19224925" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">DOI</a> <a href="https://www.mdpi.com/1424-8220/19/22/4925" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">HTML</a> <a href="/assets/pdf/2019%20Alireza%20Mohammadi%20%5BSensors%5D%20-%20Magnetic-based%20Soft%20Tactile%20Sensors%20with%20Deformable%20Continuous%20Force%20Transfer%20Medium%20for%20Resolving%20Contact%20Locations%20in%20Robotic%20Grasping%20and%20Manipulat.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> <a href="https://youtu.be/VBm6C_PYF64?si=aVexMnJXMhSiM-pw" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Video</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=xGVR6cQAAAAJ&amp;citation_for_view=xGVR6cQAAAAJ:u5HHmVD_uO8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-54-4285F4?logo=googlescholar&amp;labelColor=beige" alt="54 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The resolution of contact location is important in many applications in robotics and automation. This is generally done by using an array of contact or tactile receptors, which increases cost and complexity as the required resolution or area is increased. Tactile sensors have also been developed using a continuous deformable medium between the contact and the receptors, which allows few receptors to interpolate the information among them, avoiding the weakness highlighted in the former approach. The latter is generally used to measure contact force intensity or magnitude but rarely used to identify the contact locations. This paper presents a systematic design and characterisation procedure for magnetic-based soft tactile sensors (utilizing the latter approach with the deformable contact medium) with the goal of locating the contact force location. This systematic procedure provides conditions under which design parameters can be selected, supported by a selected machine learning algorithm, to achieve the desired performance of the tactile sensor in identifying the contact location. An illustrative example, which combines a particular sensor configuration (magnetic hall effect sensor as the receptor, a selected continuous medium and a selected sensing resolution) and a specific data-driven algorithm, is used to illustrate the proposed design procedure. The results of the illustrative example design demonstrates the efficacy of the proposed design procedure and the proposed sensing strategy in identifying a contact location. The resulting sensor is also tested on a robotic hand (Allegro Hand, SimLab Co) to demonstrate its application in real-world scenarios.</p> </div> </div> </div></li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Yangmengfei Xu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: January 30, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-MP4YH3XL4C"></script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>